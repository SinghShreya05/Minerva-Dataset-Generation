# -*- coding: utf-8 -*-
"""JaccardSimilarity.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DfSj4-qqG8_w0CnE_AHizOnEdjF28i9-
"""

# nltk.download('punkt')
# nltk.download('stopwords')
import os
import pandas as pd
import csv
from csv import writer
import nltk
import string

stopwords = nltk.corpus.stopwords.words('english')

def clean_text(text):
  text_new = "".join([i for i in text if i not in string.punctuation])
  words = nltk.tokenize.word_tokenize(text_new)
  # words_new = [i for i in words if i not in stopwords]
  words = " ".join(words)
  return words

def Jaccard_Similarity(doc1, doc2): 
  words_doc1 = set(clean_text(doc1).lower().split()) 
  words_doc2 = set(clean_text(doc2).lower().split())
  intersection = words_doc1.intersection(words_doc2)
  union = words_doc1.union(words_doc2)
  return float(len(intersection)) / len(union)

li = []
for root, dirnames, filenames in os.walk("/content/drive/MyDrive/Validate-Files/motosoto_diff"):
  for eachfile in filenames:
    with open(os.path.join(root,eachfile), 'r+') as f:
      contents = f.read()
    contents = contents.split('\n\n')
    text1 = " ".join(contents)
    for root_, dirnames_, filenames_ in os.walk("/content/drive/MyDrive/Validate-Files/motosoto_diff"):
      for eachfile_ in filenames_:
        li2 = []
        if eachfile == eachfile_:
          continue
        else:
          with open(os.path.join(root_,eachfile_), 'r+') as f_:
            contents_ = f_.read()
          contents_ = contents_.split('\n\n')
          text2 = " ".join(contents_)
          similarity_score = Jaccard_Similarity(text1, text2)
          li2 = [os.path.join(root,eachfile),os.path.join(root_,eachfile_),similarity_score]
          li.append(li2)
# frame = pd.concat(li, axis=0, ignore_index=True)

import csv
from csv import writer

with open('SimilarityFile.csv','a') as f:
    writer=csv.writer(f)
    # writer.writerow(li)
    writer.writerow([])
    for i in li:
      writer.writerow(i)















with open('event.csv', 'a') as f_object:

  writer_object = csv.writer(f_object)
  writer_object.writerow(li)
  f_object.close()

